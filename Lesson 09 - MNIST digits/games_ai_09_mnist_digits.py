# -*- coding: utf-8 -*-
"""Machine Learning #04 - MNIST digits

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/144zpJgrk8JfGOrTI5uNQpaFJhGXEDcHP?hl=en

**Runtime → Change runtime type → GPU**
"""

# !nvidia-smi

import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf

from tensorflow.keras.datasets import mnist

print(tf.version.VERSION)
print(np.version.version)

# Load data set
(train_x, train_y), (test_x, test_y) = mnist.load_data()

# Shape of data (count, width, height)
print("train_x shape", train_x.shape)
print("train_y shape", train_y.shape)
print("test_x shape", test_x.shape)
print("test_y shape", test_y.shape)

# Actual numeric values
print(train_y)

# Keras is expecting 4-dimensional array (samples, X, Y, channels)
# It would actually add the 4th dimension of 1 automatically for us (try disabling it) (depends on the version of TF)
train_x: np.ndarray = train_x.reshape((train_x.shape[0], 28, 28, 1))
test_x: np.ndarray = test_x.reshape((test_x.shape[0], 28, 28, 1))
print("After reshaping:")
print("train_x shape", train_x.shape)
print("test_x shape", test_x.shape)

print(train_x[0][12][12])

# RGB values are currently in the range of 0-255
# Neural networks usually have better learning performance when dealing with pixel values between 0 and 1
# The process is called normalization

# Firstly, convert the intensities to floats
train_x: np.ndarray = train_x.astype(float)
test_x: np.ndarray = test_x.astype(float)

print(train_x[0][12][12])

# Then divide all values by 255
train_x /= 255
test_x /= 255

print(train_x[0][12][12])

def plot_init(images: np.ndarray, labels: np.ndarray) -> None:
    plt.figure(figsize=(20, 7))
    for i in range(0, 30):
        plt.subplot(3, 10, i + 1)
        plt.grid(False)
        plt.xticks([])
        plt.yticks([])
        plt.imshow(images[i].reshape((28, 28)), cmap="binary")
        plt.xlabel(labels[i], fontsize=24)
    plt.show()


# It is advisable to always check the loaded data
plot_init(train_x, train_y)

# Let's start with a simple model

# It won't have good results and we will come back later and try to change it

# tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(2, 2), padding="same", activation=tf.nn.relu),
# tf.keras.layers.MaxPooling2D(pool_size=(4, 2), strides=(2, 1), padding="same"),

model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=[28, 28, 1]),
    tf.keras.layers.Flatten(),
    # input image has 28 pixels in width and 28 pixels in height -> we need to flatten it into "1D array"
    tf.keras.layers.Dense(300, activation=tf.nn.relu),
    tf.keras.layers.Dense(30, activation=tf.nn.relu),
    tf.keras.layers.Dense(10, activation=tf.nn.softmax)  # 10 neurons because our domain has 10 classes (digits from 0 to 9)
])
# activations - sigmoid, relu, relu6, leaky_relu, selu, gelu, tanh

# Summary of the network layers and its parameters
model.summary()

model.compile(
    # optimizer="adam",
    optimizer=tf.keras.optimizers.Adam(),
    # optimizer=tf.keras.optimizers.SGD(),
    # optimizer=tf.train.AdamOptimizer(),
    # optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.01),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

# Batch size determines how often to perform backpropagation
# Bigger value can speed up training, but requires more memory
BATCH_SIZE: int = 1000

# Train the neural network for 5 epochs - run through the train data 5 times
model.fit(x=train_x, y=train_y, epochs=5, batch_size=BATCH_SIZE)

# Evaluate the model on test data set
test_loss, test_accuracy = model.evaluate(x=test_x, y=test_y, steps=1, verbose=False)
print("Loss on the test set:", test_loss)
print("Accuracy on the test set:", test_accuracy)

def plot_image(index: int, predictions: np.ndarray, test_images: np.ndarray, test_labels: np.ndarray) -> None:
    predictions_array, img, true_label = predictions[index], test_images[index], test_labels[index]

    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(img.reshape((28, 28)), cmap="binary")

    predicted_label = np.argmax(predictions_array).item(0)
    if predicted_label == true_label:
        color = "blue"
    else:
        color = "red"

    plt.xlabel(
        "{} {:2.0f}% ({})".format(predicted_label, 100 * np.max(predictions_array), true_label),
        color=color,
        fontsize=17
    )


def plot_value(index: int, predictions: np.ndarray, test_labels: np.ndarray) -> None:
    prediction, true_label = predictions[index], test_labels[index]

    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    this_plot = plt.bar(range(10), prediction, color="#777777")
    plt.ylim([0, 1])
    predicted_label = np.argmax(prediction)

    this_plot[predicted_label].set_color("red")
    this_plot[true_label].set_color("blue")


def plot_result(predictions: np.ndarray, test_images: np.ndarray, test_labels: np.ndarray, offset: int = 0) -> None:
    rows: int = 4
    cols: int = 5
    plt.figure(figsize=(2 * 2 * cols, 2 * rows))
    for i in range(rows * cols):
        if i == len(predictions):
            break
        plt.subplot(rows, 2 * cols, 2 * i + 1)
        ii: int = i + offset
        plot_image(ii, predictions, test_images, test_labels)

        plt.subplot(rows, 2 * cols, 2 * i + 2)
        plot_value(ii, predictions, test_labels)
    plt.show()

# Predicting on the test set
predicted_y: np.ndarray = model.predict(test_x)

# Plotting the predicted values
# Correct predictions in blue. Incorrect predictions in red.
plot_result(predicted_y, test_x, test_y)  # test_y is true y

def plot_wrong_predictions(predictions: np.ndarray, test_images: np.ndarray, test_labels: np.ndarray, offset: int = 0):
    i: int = 0
    rows: int = 3
    cols: int = 5
    plt.figure(figsize=(2 * 2 * cols, 2 * rows))
    for j in range(len(predictions)):
        if i >= rows * cols:
            break

        # skip if prediction is correct
        true_label: np.ndarray = test_labels[j]
        predicted_label: np.ndarray = np.argmax(predictions[j])
        if predicted_label == true_label:
            continue

        # skip wrong predictions until offset is zero
        if offset > 0:
            offset -= 1
            continue

        plt.subplot(rows, 2 * cols, 2 * i + 1)
        plot_image(j, predictions, test_images, test_labels)

        plt.subplot(rows, 2 * cols, 2 * i + 2)
        plot_value(j, predictions, test_labels)
        i += 1
    plt.show()


# Plotting only wrong predictions - skipping the correct ones
# Very useful when already having a good model and trying to figure out which values are problematic
plot_wrong_predictions(predicted_y, test_x, test_y)

# And now the most interesting part:
# For our model, the whole world consists of digits of values from 0 to 9.
# It has absolutely no knowledge of anything else - it even does not "know" there can be anything else.
# So, what happens when you give some other image without any digit?
# Well, it will guess (sometimes confidently) that it is a digit of some value.
# Always keep in mind that it will give you a prediction on ANY image.
# It is still up to you to decide if it makes sense to ask for such a prediction.
# Let's investigate...

cross_data: np.ndarray = np.array([
    [255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255],
    [0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0],
    [0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0],
    [0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0],
    [0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0],
    [0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0],
    [0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0],
    [0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0],
    [255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255]
], dtype=np.uint8)

cross: np.ndarray = np.array([cross_data]).reshape((1, 28, 28, 1))
predicted_y: np.ndarray = model.predict(cross)

# The function expects true label, let's give it 0. But it does not matter what you give it, it is just for plotting.
plot_result(predicted_y, cross, np.array([0]))

# Because MNIST is a multiclass classification problem, these metrics are commonly defined per-class (often using a "one-vs-rest" approach).

# Let's look at confusion matrix data for classification of number 7

# The target digit, any digit from 0 to 9
digit = 0

# Get predicted classes
test_pred_classes = np.argmax(model.predict(test_x), axis=1)

# True Positive: predicted digit and is actually digit
TP = np.sum((test_pred_classes == digit) & (test_y == digit))

# False Positive: predicted digit, actually something else
FP = np.sum((test_pred_classes == digit) & (test_y != digit))

# False Negative: predicted something else, actually digit
FN = np.sum((test_pred_classes != digit) & (test_y == digit))

# True Negative: predicted something else, actually something else
TN = np.sum((test_pred_classes != digit) & (test_y != digit))

# Calculate metrics (with small value to avoid zero division)
accuracy = (TP + TN) / (TP + FP + TN + FN)
precision = TP / (TP + FP)
recall = TP / (TP + FN)
f1_score = 2 * (precision * recall) / (precision + recall)

print(f"Digit: {digit}")
print(f"TP: {TP}, FP: {FP}, FN: {FN}, TN: {TN}")
print(f"accuracy: {accuracy}")
print(f"precision: {precision}")
print(f"recall: {recall}")
print(f"f1_score: {f1_score}")